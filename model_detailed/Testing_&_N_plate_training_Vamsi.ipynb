{"cells":[{"cell_type":"markdown","metadata":{"id":"GpGDkDDBhH2g"},"source":["# Test the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"52ra0f07gtHO","outputId":"f11f4e94-7f62-404e-f5bf-1f7674a4b7f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/facebookresearch/detectron2.git@main\n","  Cloning https://github.com/facebookresearch/detectron2.git (to revision main) to /tmp/pip-req-build-2o_75nes\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-2o_75nes\n","  Resolved https://github.com/facebookresearch/detectron2.git to commit 9604f5995cc628619f0e4fd913453b4d7d61db3f\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.0.8)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.5.0)\n","Collecting yacs>=0.1.8 (from detectron2==0.6)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n","Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n","  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n","Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting hydra-core>=1.1 (from detectron2==0.6)\n","  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n","Collecting black (from detectron2==0.6)\n","  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n","Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n","Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n","  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.70.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (4.25.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n","Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n"]}],"source":["pip install 'git+https://github.com/facebookresearch/detectron2.git@main'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"syOcworugtJ_"},"outputs":[],"source":["import detectron2\n","print(\"✅ Detectron2 installed successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"elapsed":9592,"status":"error","timestamp":1740825121622,"user":{"displayName":"foodwaste","userId":"16838641789027655120"},"user_tz":-330},"id":"NNlJt-gVgtEH","outputId":"08cc5cb2-b702-4e8e-d2ba-0e502f1d0709"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"❌ Config file not found: /content/model_files/config.pkl","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-98ea78298ef3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# **Step 2: Load Model Configuration**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"❌ Config file not found: {config_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: ❌ Config file not found: /content/model_files/config.pkl"]}],"source":["import os\n","import torch\n","import pickle\n","import json\n","import cv2\n","import zipfile\n","import shutil\n","from detectron2.config import get_cfg\n","from detectron2.engine import DefaultPredictor\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog\n","from google.colab import files\n","\n","# **Step 1: Define Model Files Path (No Extraction Needed)**\n","model_dir = \"/content/model_files\"\n","model_weights_path = os.path.join(model_dir, \"model_final.pth\")\n","config_path = os.path.join(model_dir, \"config.pkl\")\n","metadata_path = os.path.join(model_dir, \"metadata.json\")\n","\n","# **Step 2: Load Model Configuration**\n","if not os.path.exists(config_path):\n","    raise FileNotFoundError(f\"❌ Config file not found: {config_path}\")\n","\n","with open(config_path, \"rb\") as f:\n","    cfg = pickle.load(f)\n","\n","cfg.MODEL.WEIGHTS = model_weights_path  # Assign trained weights\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Confidence threshold\n","cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# **Step 3: Load Metadata**\n","if not os.path.exists(metadata_path):\n","    raise FileNotFoundError(f\"❌ Metadata file not found: {metadata_path}\")\n","\n","with open(metadata_path, \"r\") as f:\n","    metadata_dict = json.load(f)\n","\n","metadata = MetadataCatalog.get(\"my_custom_train_v2\")\n","metadata.set(thing_classes=metadata_dict[\"thing_classes\"])\n","\n","# **Step 4: Load Model for Inference**\n","predictor = DefaultPredictor(cfg)\n","print(\"✅ Model loaded successfully!\")\n","\n","# **Step 5: Extract Test Images**\n","test_zip_path = \"test.zip\"\n","test_extract_dir = \"./test_images\"\n","\n","if not os.path.exists(test_extract_dir):\n","    os.makedirs(test_extract_dir)\n","\n","with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(test_extract_dir)\n","\n","print(f\"✅ Extracted test images to {test_extract_dir}\")\n","\n","# **Step 6: Run Inference on All Test Images**\n","output_dir = \"./test_predicted\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Get all image files in the extracted folder\n","image_extensions = (\".jpg\", \".jpeg\", \".png\")\n","test_images = [f for f in os.listdir(test_extract_dir) if f.lower().endswith(image_extensions)]\n","\n","if not test_images:\n","    print(\"❌ No valid images found in the test directory.\")\n","else:\n","    print(f\"✅ Found {len(test_images)} images. Running inference...\")\n","\n","    for img_name in test_images:\n","        img_path = os.path.join(test_extract_dir, img_name)\n","        output_img_path = os.path.join(output_dir, img_name)\n","\n","        # Load image\n","        image = cv2.imread(img_path)\n","\n","        if image is None:\n","            print(f\"❌ Error loading {img_name}. Skipping...\")\n","            continue\n","\n","        # Perform inference\n","        outputs = predictor(image)\n","\n","        # Visualize results\n","        v = Visualizer(image[:, :, ::-1], metadata=metadata, scale=1.0)\n","        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","        output_img = out.get_image()[:, :, ::-1]\n","\n","        # Save the output\n","        cv2.imwrite(output_img_path, output_img)\n","        print(f\"✅ Saved prediction: {output_img_path}\")\n","\n","print(f\"✅ All predictions saved in {output_dir}\")\n","\n","# **Step 7: Zip the Output Folder**\n","zip_output_path = \"test_predicted.zip\"\n","shutil.make_archive(\"test_predicted\", 'zip', output_dir)\n","print(f\"✅ Created zip file: {zip_output_path}\")\n","\n","# **Step 8: Download the Zip File**\n","files.download(zip_output_path)\n","print(\"✅ Downloading test_predicted.zip...\")\n"]},{"cell_type":"markdown","source":["# Train empty plates\n"],"metadata":{"id":"DMMg7rfuPSG5"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"hFjnNRiEgtMl"},"outputs":[],"source":["import os\n","import torch\n","import pickle\n","import json\n","import cv2\n","import zipfile\n","import random\n","import numpy as np\n","import detectron2\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.engine import DefaultTrainer\n","from detectron2.config import get_cfg\n","from detectron2.engine import DefaultPredictor\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","\n","# **Step 1: Keep the Previous Training Data**\n","PREV_MODEL_DIR = \"./model_files\"  # Directory where the old model is saved\n","OUTPUT_DIR = \"./output_finetuned\"  # New output directory for fine-tuned model\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# **Step 2: Extract and Register the New Dataset**\n","data_zip_path = \"/content/plate.zip\"\n","data_extract_dir = \"./plate_data\"\n","annotations_file = \"/content/labels_plates_segmentation_2025-02-27-02-52-56.json\"\n","\n","if not os.path.exists(data_extract_dir):\n","    os.makedirs(data_extract_dir)\n","    with zipfile.ZipFile(data_zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(data_extract_dir)\n","    print(f\"✅ Extracted new dataset to {data_extract_dir}\")\n","\n","# Register dataset in Detectron2\n","register_coco_instances(\"plate_dataset\", {}, annotations_file, data_extract_dir)\n","metadata = MetadataCatalog.get(\"plate_dataset\")\n","dataset_dicts = DatasetCatalog.get(\"plate_dataset\")\n","\n","# **Step 3: Print Labeled Samples**\n","print(f\"✅ Total labeled images: {len(dataset_dicts)}\")\n","for d in random.sample(dataset_dicts, min(3, len(dataset_dicts))):  # Show 3 samples\n","    img_path = d[\"file_name\"]\n","\n","    if not os.path.exists(img_path):\n","        print(f\"❌ Image not found: {img_path}. Skipping...\")\n","        continue\n","\n","    img = cv2.imread(img_path)\n","    if img is None:\n","        print(f\"❌ Error loading {img_path}. Skipping...\")\n","        continue\n","\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n","    vis = visualizer.draw_dataset_dict(d)\n","    output_sample_path = f\"./sample_{os.path.basename(img_path)}\"\n","    cv2.imwrite(output_sample_path, vis.get_image()[:, :, ::-1])\n","    print(f\"✅ Saved labeled sample: {output_sample_path}\")\n","\n","# **Step 4: Load the Pre-Trained Model for Fine-Tuning**\n","config_path = os.path.join(PREV_MODEL_DIR, \"config.pkl\")\n","model_weights_path = os.path.join(PREV_MODEL_DIR, \"model_final.pth\")\n","\n","with open(config_path, \"rb\") as f:\n","    cfg = pickle.load(f)\n","\n","cfg.DATASETS.TRAIN = (\"plate_dataset\",)\n","cfg.DATASETS.TEST = ()  # No testing during training\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.SOLVER.BASE_LR = 0.00025  # Lower learning rate for fine-tuning\n","cfg.SOLVER.MAX_ITER = 500  # Fewer iterations for fine-tuning\n","cfg.MODEL.WEIGHTS = model_weights_path  # Load previous trained weights\n","cfg.OUTPUT_DIR = OUTPUT_DIR\n","\n","# **Step 5: Train the Model on the New Dataset**\n","trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()\n","\n","# **Step 6: Save the Fine-Tuned Model**\n","fine_tuned_model_path = os.path.join(OUTPUT_DIR, \"model_finetuned.pth\")\n","torch.save(trainer.model.state_dict(), fine_tuned_model_path)\n","print(f\"✅ Fine-tuned model saved at {fine_tuned_model_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V9zF1tShgtU1"},"outputs":[],"source":["\n","# **Step 7: Run Inference on a Test Image**\n","test_image = \"test_image.jpg\"  # Change this to your actual test image path\n","\n","# Check if test image exists\n","if not os.path.exists(test_image):\n","    print(f\"❌ Test image not found: {test_image}\")\n","else:\n","    image = cv2.imread(test_image)\n","    if image is None:\n","        print(f\"❌ Error loading test image: {test_image}\")\n","    else:\n","        predictor = DefaultPredictor(cfg)\n","        outputs = predictor(image)\n","\n","        v = Visualizer(image[:, :, ::-1], metadata=metadata, scale=1.0)\n","        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","        output_img_path = os.path.join(OUTPUT_DIR, \"test_prediction.jpg\")\n","        cv2.imwrite(output_img_path, out.get_image()[:, :, ::-1])\n","        print(f\"✅ Saved inference output at {output_img_path}\")\n","\n","from google.colab import files\n","\n","# Download the predicted image\n","if os.path.exists(output_img_path):\n","    files.download(output_img_path)\n","    print(f\"✅ Downloading {output_img_path}...\")\n","else:\n","    print(\"❌ No predicted image found to download.\")\n"]},{"cell_type":"markdown","metadata":{"id":"ZVQYi4iT5GA7"},"source":["# Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKNfXVn25ITN"},"outputs":[],"source":["from detectron2.data import transforms as T\n","\n","# Define a set of transformations\n","augmentations = T.AugmentationList([\n","    T.RandomFlip(horizontal=True, vertical=False),  # Flip horizontally\n","    T.RandomRotation(angle=[-15, 15]),  # Rotate between -15° and 15°\n","    T.RandomBrightness(0.8, 1.2),  # Adjust brightness\n","    T.RandomContrast(0.8, 1.2),  # Adjust contrast\n","    T.RandomSaturation(0.8, 1.2),  # Adjust saturation\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcKG1SkH5LF-"},"outputs":[],"source":["def custom_mapper(dataset_dict):\n","    dataset_dict = dataset_dict.copy()  # Make a copy\n","    image = cv2.imread(dataset_dict[\"file_name\"])  # Load image\n","\n","    # Apply augmentations\n","    aug_input = T.AugInput(image)\n","    transform = augmentations(aug_input)\n","    image = aug_input.image  # Get augmented image\n","\n","    # Apply transformations to annotations\n","    for anno in dataset_dict[\"annotations\"]:\n","        anno[\"bbox\"] = transform.apply_box(anno[\"bbox\"])\n","\n","    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1))\n","    return dataset_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ma3AEh8m5XiC"},"outputs":[],"source":["from detectron2.data import DatasetMapper\n","from detectron2.data.build import build_detection_train_loader\n","\n","cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = True  # Ignore images without objects\n","train_loader = build_detection_train_loader(cfg, mapper=custom_mapper)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}